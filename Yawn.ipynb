{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "319d808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import cv2\n",
    "import numpy as np\n",
    "from playsound import playsound\n",
    "import threading\n",
    "from mtcnn import MTCNN\n",
    "#from retinaface import RetinaFace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c71c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['eyeclose', 'normal', 'yawn']\n"
     ]
    }
   ],
   "source": [
    "data_dir = r\"C:\\Users\\phtac\\OneDrive\\Documents\\Deep learning\\prj2\\data\\data\\processed\"  \n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(root=f'{data_dir}/{x}', transform=data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True)\n",
    "               for x in ['train', 'test']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Classes:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b5f7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  \n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd9c427d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "train Loss: 0.5533 Acc: 0.8231\n",
      "test Loss: 0.3065 Acc: 0.9463\n",
      "Epoch 2/30\n",
      "train Loss: 0.2359 Acc: 0.9513\n",
      "test Loss: 0.1865 Acc: 0.9691\n",
      "Epoch 3/30\n",
      "train Loss: 0.1718 Acc: 0.9637\n",
      "test Loss: 0.1380 Acc: 0.9756\n",
      "Epoch 4/30\n",
      "train Loss: 0.1474 Acc: 0.9663\n",
      "test Loss: 0.1313 Acc: 0.9739\n",
      "Epoch 5/30\n",
      "train Loss: 0.1262 Acc: 0.9699\n",
      "test Loss: 0.0935 Acc: 0.9870\n",
      "Epoch 6/30\n",
      "train Loss: 0.1145 Acc: 0.9711\n",
      "test Loss: 0.0845 Acc: 0.9821\n",
      "Epoch 7/30\n",
      "train Loss: 0.1083 Acc: 0.9690\n",
      "test Loss: 0.0753 Acc: 0.9886\n",
      "Epoch 8/30\n",
      "train Loss: 0.0939 Acc: 0.9758\n",
      "test Loss: 0.0643 Acc: 0.9902\n",
      "Epoch 9/30\n",
      "train Loss: 0.0925 Acc: 0.9749\n",
      "test Loss: 0.0621 Acc: 0.9886\n",
      "Epoch 10/30\n",
      "train Loss: 0.0882 Acc: 0.9761\n",
      "test Loss: 0.0574 Acc: 0.9870\n",
      "Epoch 11/30\n",
      "train Loss: 0.0802 Acc: 0.9787\n",
      "test Loss: 0.0634 Acc: 0.9870\n",
      "Epoch 12/30\n",
      "train Loss: 0.0719 Acc: 0.9811\n",
      "test Loss: 0.0521 Acc: 0.9902\n",
      "Epoch 13/30\n",
      "train Loss: 0.0681 Acc: 0.9811\n",
      "test Loss: 0.0463 Acc: 0.9935\n",
      "Epoch 14/30\n",
      "train Loss: 0.0691 Acc: 0.9805\n",
      "test Loss: 0.0466 Acc: 0.9886\n",
      "Epoch 15/30\n",
      "train Loss: 0.0656 Acc: 0.9820\n",
      "test Loss: 0.0448 Acc: 0.9919\n",
      "Epoch 16/30\n",
      "train Loss: 0.0699 Acc: 0.9790\n",
      "test Loss: 0.0381 Acc: 0.9935\n",
      "Epoch 17/30\n",
      "train Loss: 0.0701 Acc: 0.9767\n",
      "test Loss: 0.0403 Acc: 0.9935\n",
      "Epoch 18/30\n",
      "train Loss: 0.0703 Acc: 0.9781\n",
      "test Loss: 0.0386 Acc: 0.9919\n",
      "Epoch 19/30\n",
      "train Loss: 0.0689 Acc: 0.9784\n",
      "test Loss: 0.0357 Acc: 0.9919\n",
      "Epoch 20/30\n",
      "train Loss: 0.0716 Acc: 0.9767\n",
      "test Loss: 0.0325 Acc: 0.9951\n",
      "Epoch 21/30\n",
      "train Loss: 0.0737 Acc: 0.9755\n",
      "test Loss: 0.0326 Acc: 0.9967\n",
      "Epoch 22/30\n",
      "train Loss: 0.0560 Acc: 0.9817\n",
      "test Loss: 0.0307 Acc: 0.9951\n",
      "Epoch 23/30\n",
      "train Loss: 0.0600 Acc: 0.9805\n",
      "test Loss: 0.0287 Acc: 0.9951\n",
      "Epoch 24/30\n",
      "train Loss: 0.0559 Acc: 0.9817\n",
      "test Loss: 0.0294 Acc: 0.9935\n",
      "Epoch 25/30\n",
      "train Loss: 0.0510 Acc: 0.9858\n",
      "test Loss: 0.0425 Acc: 0.9902\n",
      "Epoch 26/30\n",
      "train Loss: 0.0477 Acc: 0.9861\n",
      "test Loss: 0.0280 Acc: 0.9935\n",
      "Epoch 27/30\n",
      "train Loss: 0.0493 Acc: 0.9855\n",
      "test Loss: 0.0270 Acc: 0.9951\n",
      "Epoch 28/30\n",
      "train Loss: 0.0626 Acc: 0.9799\n",
      "test Loss: 0.0323 Acc: 0.9919\n",
      "Epoch 29/30\n",
      "train Loss: 0.0552 Acc: 0.9846\n",
      "test Loss: 0.0267 Acc: 0.9935\n",
      "Epoch 30/30\n",
      "train Loss: 0.0543 Acc: 0.9841\n",
      "test Loss: 0.0310 Acc: 0.9919\n",
      "Best acc: 0.9967\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(image_datasets[phase])\n",
    "        epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        if phase == 'test' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "torch.save(model.state_dict(), 'yawn_resnet18.pth')\n",
    "print(f'Best acc: {best_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62dd8502",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7        \n",
    "smooth_frames = 5      \n",
    "\n",
    "\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.load_state_dict(torch.load('yawn_resnet18.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "\n",
    "detector = MTCNN()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "prev_label = \"normal\"\n",
    "conf_buffer = []\n",
    "yawn_count = 0\n",
    "eyes_closed_start = None\n",
    "Close_threshold = 5\n",
    "alert_playing = False\n",
    "\n",
    "\n",
    "def play_alert(file):\n",
    "    threading.Thread(target=playsound, args=(file,), daemon=True).start()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = detector.detect_faces(rgb_frame)\n",
    "\n",
    "    if results:\n",
    "        \n",
    "        face = max(results, key=lambda r: r['confidence'])\n",
    "        x, y, w, h = face['box']\n",
    "        x, y = max(0, x), max(0, y)\n",
    "        face_roi = rgb_frame[y:y+h, x:x+w]\n",
    "\n",
    "       \n",
    "        img_pil = transforms.ToPILImage()(face_roi)\n",
    "        img_tensor = transform(img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(img_tensor)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
    "            conf, pred_class = torch.max(probs, dim=0)\n",
    "\n",
    "        conf_value = conf.item()\n",
    "        label = class_names[pred_class.item()]\n",
    "\n",
    "        \n",
    "        if conf_value < threshold:\n",
    "            label = prev_label\n",
    "        else:\n",
    "            conf_buffer.append(conf_value)\n",
    "            if len(conf_buffer) > smooth_frames:\n",
    "                conf_buffer.pop(0)\n",
    "            avg_conf = np.mean(conf_buffer)\n",
    "            if avg_conf > threshold:\n",
    "                prev_label = label\n",
    "\n",
    "        if conf_value < threshold:\n",
    "            label = prev_label\n",
    "        else:\n",
    "            conf_buffer.append(conf_value)\n",
    "            if len(conf_buffer) > smooth_frames:\n",
    "                conf_buffer.pop(0)\n",
    "            avg_conf = np.mean(conf_buffer)\n",
    "            if avg_conf > threshold:\n",
    "                prev_label = label\n",
    "\n",
    "        curr_time = time.time()\n",
    "        if prev_label == \"yawn\":\n",
    "            yawn_count += 1\n",
    "            if yawn_count >= 10 and alert_playing == False:\n",
    "                play_alert('Soft Alarm Sound Effect.mp3')\n",
    "                yawn_count = 0\n",
    "\n",
    "        elif prev_label == \"eyeclose\":\n",
    "            if eyes_closed_start is None:\n",
    "                eyes_closed_start = curr_time\n",
    "            elif curr_time - eyes_closed_start >= Close_threshold and not alert_playing:\n",
    "                play_alert('Danger Alarm Sound Effect.mp3')\n",
    "                alert_playing = False\n",
    "        else:\n",
    "            eyes_closed_start = None\n",
    "            alert_playing = False\n",
    "            yawn_count = 0\n",
    "                \n",
    "       \n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        text = f\"{prev_label} ({conf_value:.2f})\"\n",
    "        cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.9, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    else:\n",
    "        cv2.putText(frame, \"No face detected\", (20, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Yawning Detection (MTCNN)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
